{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":77305,"databundleVersionId":8428710,"sourceType":"competition"},{"sourceId":1379553,"sourceType":"datasetVersion","datasetId":804753}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1> Accident Detection From CCTV Footage </h1>","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-06-07T05:40:49.821544Z","iopub.execute_input":"2024-06-07T05:40:49.822381Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Description :</h2>\n<h3>Dataset Description :</h3>\n<p> Accident Detection dataset collected from the CCTV footages containing a total of 990 accident and non-accident frames collected from road videos available on YouTube. The 990 files are split in the 791 training frames, 101 test frames and 98 validation frames.\n791 (369-accident, 492-non accident) Training, 101 Test and 98 Validation (52-accident, 46-non accident) frames split in Accident and Non-accident frames in all the three folders. </p>\n\n<h3>Problem Analysis: </h3>\n<pre>\nInput : Images that can be accident/Non Accident\nOutput : 0(Indicates No Accident)\n         1(Indicates Accident)\n</pre>","metadata":{}},{"cell_type":"markdown","source":"<h1>1. Loading Data</h1>","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:32.719673Z","iopub.execute_input":"2024-05-16T10:29:32.720589Z","iopub.status.idle":"2024-05-16T10:29:32.733924Z","shell.execute_reply.started":"2024-05-16T10:29:32.720533Z","shell.execute_reply":"2024-05-16T10:29:32.732809Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:32.758305Z","iopub.execute_input":"2024-05-16T10:29:32.759506Z","iopub.status.idle":"2024-05-16T10:29:44.994392Z","shell.execute_reply.started":"2024-05-16T10:29:32.759471Z","shell.execute_reply":"2024-05-16T10:29:44.993498Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tr_data_dir = os.path.join(\"/kaggle/input/accident-detection-from-cctv-footage/data/train\")\ntr_data = tf.keras.utils.image_dataset_from_directory(\n                            tr_data_dir,image_size=(256, 256),\n                            seed = 12332\n                            ) \n# here we resize image to 256*256\n# We randomly shuffled data with seed\n# we will do automatic feature extraction later usiing filtering and pooling layers","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:44.99624Z","iopub.execute_input":"2024-05-16T10:29:44.996837Z","iopub.status.idle":"2024-05-16T10:29:47.841565Z","shell.execute_reply.started":"2024-05-16T10:29:44.996808Z","shell.execute_reply":"2024-05-16T10:29:47.840386Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We can't access this data directly by data[0] ; this will give us an error\n# We have to get an iterator for this & call iterator to get each batch of 32  images \n\ntr_data_iterator = tr_data.as_numpy_iterator()\ntr_batch = tr_data_iterator.next()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:47.843248Z","iopub.execute_input":"2024-05-16T10:29:47.843708Z","iopub.status.idle":"2024-05-16T10:29:49.479935Z","shell.execute_reply.started":"2024-05-16T10:29:47.843669Z","shell.execute_reply":"2024-05-16T10:29:49.478867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(tr_batch[0]) # this gives Num of Images in training Batch","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:49.482856Z","iopub.execute_input":"2024-05-16T10:29:49.483629Z","iopub.status.idle":"2024-05-16T10:29:49.494413Z","shell.execute_reply.started":"2024-05-16T10:29:49.48359Z","shell.execute_reply":"2024-05-16T10:29:49.493257Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>2.Dataset visualisation </h2>","metadata":{}},{"cell_type":"code","source":"def label_to_category(label):\n    if(label == 1):\n        return \"No Accident\"\n    elif label == 0:\n        return \"Accident\"\n    else :\n        return \"error\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:49.49677Z","iopub.execute_input":"2024-05-16T10:29:49.497452Z","iopub.status.idle":"2024-05-16T10:29:49.503278Z","shell.execute_reply.started":"2024-05-16T10:29:49.497417Z","shell.execute_reply":"2024-05-16T10:29:49.501973Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plotting full batch of 32 images together\n\ncols = 4 \nrows = 4\nfig, ax = plt.subplots(nrows= rows , ncols= cols,figsize=(15,15),layout='constrained')\nfig.tight_layout(pad=2)\n\n\n\n\nfor outer_index, img in enumerate(tr_batch[0][:]):\n    if outer_index >= rows*cols:\n        break\n        \n    if (outer_index % cols == 0):\n        for inner_index, img in enumerate(tr_batch[0][outer_index:outer_index+cols]):\n    \n        \n            ax[outer_index//cols][inner_index].imshow(img.astype(int))\n\n            label = label_to_category(tr_batch[1][outer_index + inner_index])        \n    \n            \n            ax[outer_index//cols][inner_index].set_aspect(1)\n\n            num_label = tr_batch[1][outer_index + inner_index]\n            \n            ax[outer_index//cols][inner_index].axis(\"off\")\n            ax[outer_index//cols][inner_index].title.set_text(label)\n            \n\nplt.savefig(\"test.png\")       \nplt.show()\n\n\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-16T10:29:49.504959Z","iopub.execute_input":"2024-05-16T10:29:49.50563Z","iopub.status.idle":"2024-05-16T10:29:54.524816Z","shell.execute_reply.started":"2024-05-16T10:29:49.50559Z","shell.execute_reply":"2024-05-16T10:29:54.523217Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>2. Preprocessing Data </h1>","metadata":{}},{"cell_type":"code","source":"# Normalizing pixels value between between 0 & 1 \ntr_data = tr_data.map(lambda x,y: (x/255, y))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:54.526281Z","iopub.execute_input":"2024-05-16T10:29:54.526653Z","iopub.status.idle":"2024-05-16T10:29:54.562604Z","shell.execute_reply.started":"2024-05-16T10:29:54.52662Z","shell.execute_reply":"2024-05-16T10:29:54.561585Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tr_batch = tr_data.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:54.563911Z","iopub.execute_input":"2024-05-16T10:29:54.564222Z","iopub.status.idle":"2024-05-16T10:29:55.399405Z","shell.execute_reply.started":"2024-05-16T10:29:54.564195Z","shell.execute_reply":"2024-05-16T10:29:55.398498Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking pixel min/max pixel values after normalization\nprint(\"Max pixel value : \",tr_batch[0].max())\nprint(\"Min pixel value : \",tr_batch[0].min())","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:55.400731Z","iopub.execute_input":"2024-05-16T10:29:55.401057Z","iopub.status.idle":"2024-05-16T10:29:55.411198Z","shell.execute_reply.started":"2024-05-16T10:29:55.401018Z","shell.execute_reply":"2024-05-16T10:29:55.410094Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#lets see training data after normalization\n\ncols = 4\nrows = 4\nfig, ax = plt.subplots(nrows= rows , ncols= cols,figsize=(15,15),layout='constrained')\nfig.tight_layout(pad=2)\n\n\n\n\nfor outer_index, img in enumerate(tr_batch[0][:]):\n    if outer_index >= rows*cols:\n        break\n        \n    if (outer_index % cols == 0):\n        for inner_index, img in enumerate(tr_batch[0][outer_index:outer_index+cols]):\n    \n        \n            ax[outer_index//cols][inner_index].imshow(img)\n            if(tr_batch[1][outer_index + inner_index] == 0):\n               label = \" Accident\"\n            else: label = \" No Accident\"\n    \n            \n    \n            \n            ax[outer_index//cols][inner_index].set_aspect(1)\n\n            num_label = tr_batch[1][outer_index + inner_index]\n            \n            ax[outer_index//cols][inner_index].axis(\"off\")\n            ax[outer_index//cols][inner_index].title.set_text(label)\n            \n\nplt.savefig(\"test.png\")       \nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:29:55.416944Z","iopub.execute_input":"2024-05-16T10:29:55.417268Z","iopub.status.idle":"2024-05-16T10:30:00.158342Z","shell.execute_reply.started":"2024-05-16T10:29:55.417241Z","shell.execute_reply":"2024-05-16T10:30:00.157176Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>Loading Validation data for Hyper-parameter Turing</h2>","metadata":{}},{"cell_type":"code","source":"val_data_dir = os.path.join(\"/kaggle/input/accident-detection-from-cctv-footage/data/val\")\nval_data = tf.keras.utils.image_dataset_from_directory(val_data_dir)\nval_data_iterator = val_data.as_numpy_iterator()\nval_batch = val_data_iterator.next()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:00.159717Z","iopub.execute_input":"2024-05-16T10:30:00.160046Z","iopub.status.idle":"2024-05-16T10:30:00.715836Z","shell.execute_reply.started":"2024-05-16T10:30:00.160017Z","shell.execute_reply":"2024-05-16T10:30:00.714307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalizing Validation data\nval_data = val_data.map(lambda x,y: (x/255, y))\nval_batch = val_data.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:00.717417Z","iopub.execute_input":"2024-05-16T10:30:00.71779Z","iopub.status.idle":"2024-05-16T10:30:01.03126Z","shell.execute_reply.started":"2024-05-16T10:30:00.71776Z","shell.execute_reply":"2024-05-16T10:30:01.030255Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1> 3. Building CNN Architecture  </h1>\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.032593Z","iopub.execute_input":"2024-05-16T10:30:01.032906Z","iopub.status.idle":"2024-05-16T10:30:01.044671Z","shell.execute_reply.started":"2024-05-16T10:30:01.032871Z","shell.execute_reply":"2024-05-16T10:30:01.043245Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.046568Z","iopub.execute_input":"2024-05-16T10:30:01.047008Z","iopub.status.idle":"2024-05-16T10:30:01.055042Z","shell.execute_reply.started":"2024-05-16T10:30:01.046969Z","shell.execute_reply":"2024-05-16T10:30:01.053851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(32, (3,3), 1, activation='relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(16, (3,3), 1, activation='relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\n# Adding neural Layer\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.056256Z","iopub.execute_input":"2024-05-16T10:30:01.05662Z","iopub.status.idle":"2024-05-16T10:30:01.19622Z","shell.execute_reply.started":"2024-05-16T10:30:01.056591Z","shell.execute_reply":"2024-05-16T10:30:01.195016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.197677Z","iopub.execute_input":"2024-05-16T10:30:01.198081Z","iopub.status.idle":"2024-05-16T10:30:01.212945Z","shell.execute_reply.started":"2024-05-16T10:30:01.198044Z","shell.execute_reply":"2024-05-16T10:30:01.212034Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-16T10:30:01.214383Z","iopub.execute_input":"2024-05-16T10:30:01.214797Z","iopub.status.idle":"2024-05-16T10:30:01.245048Z","shell.execute_reply.started":"2024-05-16T10:30:01.21476Z","shell.execute_reply":"2024-05-16T10:30:01.243968Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1> 4.  Training Neural Network </h1>","metadata":{}},{"cell_type":"code","source":"# setting up for logging \nlogdir='logs'\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.24633Z","iopub.execute_input":"2024-05-16T10:30:01.246652Z","iopub.status.idle":"2024-05-16T10:30:01.251683Z","shell.execute_reply.started":"2024-05-16T10:30:01.246623Z","shell.execute_reply":"2024-05-16T10:30:01.250554Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hist = model.fit(tr_data, epochs=20, validation_data=val_data, callbacks=[tensorboard_callback])\nmodel.save(\"/kaggle/working/accidents.keras\")                                                     ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:30:01.253307Z","iopub.execute_input":"2024-05-16T10:30:01.253819Z","iopub.status.idle":"2024-05-16T10:31:12.969038Z","shell.execute_reply.started":"2024-05-16T10:30:01.253737Z","shell.execute_reply":"2024-05-16T10:31:12.968079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hist.history ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:12.970478Z","iopub.execute_input":"2024-05-16T10:31:12.970805Z","iopub.status.idle":"2024-05-16T10:31:12.975727Z","shell.execute_reply.started":"2024-05-16T10:31:12.970775Z","shell.execute_reply":"2024-05-16T10:31:12.974564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>5.Seeing Training Loss and Accuracy Curve with epochs</h2>","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nplt.plot(hist.history['loss'], color='teal', label='training loss')\nplt.plot(hist.history['val_loss'], color='orange', label='val_loss')\nfig.suptitle('Loss', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"loss\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:12.977141Z","iopub.execute_input":"2024-05-16T10:31:12.977493Z","iopub.status.idle":"2024-05-16T10:31:13.284198Z","shell.execute_reply.started":"2024-05-16T10:31:12.977465Z","shell.execute_reply":"2024-05-16T10:31:13.283086Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure()\nplt.plot(hist.history['accuracy'], color='teal', label='training accuracy')\nplt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\nfig.suptitle('Accuracy', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:13.285513Z","iopub.execute_input":"2024-05-16T10:31:13.285821Z","iopub.status.idle":"2024-05-16T10:31:13.593255Z","shell.execute_reply.started":"2024-05-16T10:31:13.285793Z","shell.execute_reply":"2024-05-16T10:31:13.592201Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>6. Evaluation</h1>","metadata":{}},{"cell_type":"code","source":"test_data_dir = os.path.join(\"/kaggle/input/accident-detection-from-cctv-footage/data/test\")\ntest_data = tf.keras.utils.image_dataset_from_directory(test_data_dir)\ntest_data_iterator = test_data.as_numpy_iterator()\ntest_batch = test_data_iterator.next()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:13.594534Z","iopub.execute_input":"2024-05-16T10:31:13.594821Z","iopub.status.idle":"2024-05-16T10:31:14.150729Z","shell.execute_reply.started":"2024-05-16T10:31:13.594794Z","shell.execute_reply":"2024-05-16T10:31:14.14934Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\npre = tf.keras.metrics.Precision\nre = tf.keras.metrics.Recall()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:14.154294Z","iopub.execute_input":"2024-05-16T10:31:14.15483Z","iopub.status.idle":"2024-05-16T10:31:14.165096Z","shell.execute_reply.started":"2024-05-16T10:31:14.154782Z","shell.execute_reply":"2024-05-16T10:31:14.164075Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pre = tf.keras.metrics.Precision()\nre = tf.keras.metrics.Recall()\n\nfor batch in test_data:\n    X, y = batch\n    yhat = model.predict(X)\n    pre.update_state(y, yhat)\n    re.update_state(y, yhat)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:14.166553Z","iopub.execute_input":"2024-05-16T10:31:14.166891Z","iopub.status.idle":"2024-05-16T10:31:16.197884Z","shell.execute_reply.started":"2024-05-16T10:31:14.166863Z","shell.execute_reply":"2024-05-16T10:31:16.196673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def F1_score(precision, recall):\n    return (2*precision*recall)/(precision+recall)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:16.199373Z","iopub.execute_input":"2024-05-16T10:31:16.199791Z","iopub.status.idle":"2024-05-16T10:31:16.205754Z","shell.execute_reply.started":"2024-05-16T10:31:16.199751Z","shell.execute_reply":"2024-05-16T10:31:16.204732Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Model achieved an precision score of {:5f}\".format(pre.result()))\nprint(\"Model achieved an recall score of {:5f}\".format(re.result()))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:16.207344Z","iopub.execute_input":"2024-05-16T10:31:16.207765Z","iopub.status.idle":"2024-05-16T10:31:16.222152Z","shell.execute_reply.started":"2024-05-16T10:31:16.207715Z","shell.execute_reply":"2024-05-16T10:31:16.221061Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f1_score = F1_score(pre.result(), re.result())\nprint(\"Model achieved an F1-score of {:5f}\".format(f1_score))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:16.2273Z","iopub.execute_input":"2024-05-16T10:31:16.22766Z","iopub.status.idle":"2024-05-16T10:31:16.240166Z","shell.execute_reply.started":"2024-05-16T10:31:16.227632Z","shell.execute_reply":"2024-05-16T10:31:16.239327Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1> 7.Test just to see model working </h1>","metadata":{}},{"cell_type":"code","source":"import cv2\n\n# load random samples from samples directory\nrandom_data_dirname = os.path.join(\"/kaggle/input/accident-detection-from-cctv-footage/data/test/Accident\")\npics = [os.path.join(random_data_dirname, filename) for filename in os.listdir(random_data_dirname)]\n\n# load first file from samples\nsample = cv2.imread(pics[1], cv2.IMREAD_COLOR)\nsample = cv2.resize(sample, (256, 256))\n\nprediction = 1 - model.predict(np.expand_dims(sample/255, 0))\n\nif prediction >= 0.5: \n    label = 'Predicted class is Accident'\nelse:\n    label = 'Predicted class is Not Accident'\n\nplt.title(label)\nplt.imshow(sample)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:16.241321Z","iopub.execute_input":"2024-05-16T10:31:16.241655Z","iopub.status.idle":"2024-05-16T10:31:17.493922Z","shell.execute_reply.started":"2024-05-16T10:31:16.241628Z","shell.execute_reply":"2024-05-16T10:31:17.492821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create CSV Files for Submission","metadata":{}},{"cell_type":"code","source":"import cv2\nimport pandas as pd\n\n# load random samples from samples directory\ntest_data_dirname = os.path.join(\"/kaggle/input/accident-detection-from-cctv-footage/data/test\")\npics = [os.path.join(test_data_dirname, filename) for filename in os.listdir(test_data_dirname)]\n\n\nfilenames = []\npredictions = []\n\nfor dirname in os.listdir(test_data_dirname):\n    for filename in os.listdir(os.path.join(test_data_dirname, dirname)):\n        if not filename.endswith(\".jpg\"):\n            continue\n        filepath = os.path.join(test_data_dirname, dirname, filename)\n        \n        # load first file from samples\n        sample = cv2.imread(filepath, cv2.IMREAD_COLOR)\n        sample = cv2.resize(sample, (256, 256))\n        \n        # predict using model\n        prediction = 1 - model.predict(np.expand_dims(sample/255, 0))\n        # done because when we loaded data by default 0 label is given to first folder\n        # which is Accident but we want just opposite labels\n        # we want 0: Accident and 1: Not Accident\n        \n        filenames.append(filename)\n        \n        output = 1 if float(prediction[0][0]) >= 0.5 else 0\n        predictions.append(output)\n\ndf = pd.DataFrame(columns=[\"ID\", \"Column ID\"])\ndf[\"ID\"] = filenames\ndf[\"Column ID\"] = predictions\ndf.to_csv(\"/kaggle/working/submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:31:17.495198Z","iopub.execute_input":"2024-05-16T10:31:17.495524Z","iopub.status.idle":"2024-05-16T10:31:25.856126Z","shell.execute_reply.started":"2024-05-16T10:31:17.495496Z","shell.execute_reply":"2024-05-16T10:31:25.855266Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}